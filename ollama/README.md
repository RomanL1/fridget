Vor dem ersten start muss mann noch in die shell vom container gehen und danach folgendes ausführen:

`ollama pull llama3.3:70b-instruct-q4_K_M`

api-test.js ist ein beispiel, dass kann man lokal ausführen kann

models zum auswählen
https://ollama.com/search